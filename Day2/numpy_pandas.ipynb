{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy & Pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy and Arrays\n",
    "\n",
    "Numpy is a powerful numeric library that is essential for anyone analyzing data with Python. Numpy is a huge package that can support a multitude of tasks. Numpy is also inextricably linked to SciPy, a powerful library for scientific computing with capabilities for fitting, linear algebra, machine learning, etc. Here we are just going to cover some of the basics of numpy, but I encourage you to check out the numpy documentation pages (https://numpy.org/doc/stable/) to get an idea of the variety of things you can do.\n",
    "\n",
    "Arrays are a data type which is fundamental to Numpy. In some ways Numpy arrays are like Python lists:\n",
    "- both are used for storing data/objects\n",
    "- both are mutable (i.e. you can change their elements)\n",
    "- items can be extracted from both using indexing and slicing\n",
    "- both can be iterated over\n",
    "\n",
    "However there are key aspects of arrays that make them very different:\n",
    "- most operators act on the elements of an array instead of the array as a whole\n",
    "- arrays can only hold data of a single type\n",
    "- arrays can efficiently store large amounts of data in memory\n",
    "- arrays are of fixed size in memory, whereas lists don't have fixed size. (Question: if arrays have fixed size, how do you think [numpy.append](https://numpy.org/doc/stable/reference/generated/numpy.append.html) works?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# create some sample lists\n",
    "xlist = [1, 2, 3, 4]\n",
    "ylist = [1, 4, 9, 16]\n",
    "\n",
    "# create some sample arrays\n",
    "x = np.array([1, 2, 3, 4])\n",
    "y = np.array([1, 4, 9, 16])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check out the different behaviors between lists and arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]\n",
      "[ 4  8 12 16]\n",
      "[0.25 0.5  0.75 1.  ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(x \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(x \u001b[39m/\u001b[39m \u001b[39m4\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(xlist \u001b[39m/\u001b[39;49m \u001b[39m4\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "print(xlist * 4)\n",
    "\n",
    "print(x * 4)\n",
    "\n",
    "print(x / 4)\n",
    "\n",
    "print(xlist / 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the list was repeated 4 times, whereas each element of the array was multiplied by 4 and the result ended up being the same length.\n",
    "\n",
    "Division works element-wise for arrays, but division is not defined and produces an error when performed on a list."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating, indexing, and slicing\n",
    "\n",
    "Iterating over a 1D array looks just like iterating over a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in xlist:\n",
    "    print(val)\n",
    "\n",
    "for val in x:\n",
    "    print(val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating an N-dimensional array will iterate over slices along the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.uniform(size=(5, 5))\n",
    "\n",
    "for val in y:\n",
    "    print(val)\n",
    "\n",
    "print()\n",
    "# you could accomplish the same thing like this (but it's less readible and less efficient)\n",
    "for i in range(y.shape[0]):\n",
    "    val = y[i, :]\n",
    "    print(val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select subsets of the array using conditionals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = x[x < 2]\n",
    "xs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, setting an array equal to another does not create a new array. In other words, editing either array will modify the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to create a new array, z, that is a copy of x\n",
    "z = x\n",
    "\n",
    "# modify x\n",
    "x[3] = 10\n",
    "\n",
    "# z is modified too\n",
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the copy method if you really need a new copy of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.copy()\n",
    "x[3] = 20\n",
    "print(z)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hstack and vstack are useful to stitch together multiple arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hstack stitches together along the first dimension\n",
    "hstack = np.hstack((x, z))\n",
    "print(hstack)\n",
    "\n",
    "print()\n",
    "# vstack stitches along the last dimension\n",
    "vstack = np.vstack((x, z))\n",
    "print(vstack)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best practices\n",
    "\n",
    "- If it's important that your code is fast, it's almost always better to avoid for loops. \n",
    "- If I'm working on a complicated problem and I'm unsure whether to use a loop or array operations, I usually write it up in a loop first so that I can conceptualize the problem easier, then convert later to remove as many loops as possible.\n",
    "- Loops are often more readable than list comprehensions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Tables\n",
    "\n",
    "Pandas is a powerful data analysis package that provides tools for manipulating tabular data. This is particularly useful in many astronomical applications, such as spectroscopy, and time-series. Data is organized into rows and columns where the columns are named and recalled using arbitrary Python objects (strings are the most convenient). This is in contrast to Numpy arrays where columns can only be accessed using integer indices (however, also see [structured arrays](https://numpy.org/doc/stable/user/basics.rec.html)).\n",
    "\n",
    "Sorting, querying, merging, and aggregation are some of the most useful Pandas features, but this tutorial will only scratch the surface. See https://pandas.pydata.org/docs/ for the full documentation.\n",
    "\n",
    "\n",
    "Pandas is most useful for dealing with heterogeneous and/or large datasets, when merging or complex queries are needed, or if you have metadata associated with columns (e.g. strings as labels)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic units/objects in Pandas are the Series and DataFrame objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Lets create a sample Series object\n",
    "x = [1.0, 2.0, 4.4, 4.5, 8.8, 9.1, 8.7, 2.3, 2.4, 3.1, 5.9]\n",
    "s = pd.Series(x)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We populated a `Series` starting from a list of floating point numbers. Notice that two columns are printed in the output. Every entry in a Series has a corresponding integer index; generally these indices are created automatically. The data type stored is printed below the `Series` itself. Series objects can only store data of a single type, but any data type can be stored.\n",
    "\n",
    "A `Series` is like a single column of data in a table. A `DataFrame` is the Pandas object that represents a full table. Each column in the table is a `Series`.\n",
    "\n",
    "There are several ways to construct a Pandas `DataFrame`, including from Numpy arrays, Python dictionaries, a list of `Series` objects, reading from a CSV, reading from a URL, etc.\n",
    "\n",
    "Let's first construct a single-column `DataFrame` from our series `s`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(s, columns=[\"samples\"])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter has special support for displaying DataFrames, simply typing the variable name of a DataFrame at the end of the cell will present a nicely formatted view of the table.\n",
    "\n",
    "Let's add some more columns to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sample_base\"] = df[\"samples\"] // 1\n",
    "df[\"sample_plus1\"] = df[\"samples\"] + 1\n",
    "df[\"sample_squared\"] = df.samples.values**2\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we can access the values in a column using two different syntax."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily save/read Pandas DataFrames to/from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a CSV file\n",
    "df.to_csv(\"demo.csv\")\n",
    "\n",
    "# read back from the CSV we just saved\n",
    "df = pd.read_csv(\"demo.csv\")\n",
    "\n",
    "# a variety of other formats are supported including JSON, ASCII, etc. Each format has its own read/write methods."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices:\n",
    "\n",
    "`numpy` is more memory efficient than `pandas`, but `pandas` is often helpful for organization and common data analysis tasks. For example, if I have a set of data that has 50 data points, each with time, radial velocity, error, S-index value, H-alpha value, and starname, a `pandas` `DataFrame` will probably be easier to keep track of than a multi-dimensional numpy array, or several 1D arrays. If `pandas` sounds like it will make your life harder rather than easier, it's probably not worth using. \n",
    "\n",
    "Consider using `pandas` when your data are:\n",
    "- heterogeneous (e.g. a mix of strings, ints, and floats)\n",
    "- going to be combined with other similar data sets (e.g. I have one set of RV data, as described above, taken with the HIRES instrument, and another set from the APF instrument, and I want to extract all data taken for a given star)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activites\n",
    "\n",
    "After we go through the matplotlib/astropy tutorial, come back to these exercises in your small groups. Take some time before starting to review the context above individually, then, when everyone in your group is ready, work on the following two activities together.\n",
    "\n",
    "### Roles:\n",
    "- navigator (person with most recent birthday)\n",
    "- driver (person with farthest away birthday)\n",
    "- moderator\n",
    "\n",
    "### Product:\n",
    "- Activity 1: plot of length vs time for both arrays and lists\n",
    "- Activity 2: answer & justification for each scenario\n",
    "\n",
    "## Activity #1 \n",
    "\n",
    "Let's see how much faster it is to work with Numpy arrays over Python lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# First we'll create a long list\n",
    "length = 10000000  # must be an int\n",
    "x = list(range(length))\n",
    "\n",
    "# now lets loop over all of the elements and add one then divide by two\n",
    "# we will also use the time package to time how long it takes\n",
    "t1 = time.time()\n",
    "for i in range(len(x)):\n",
    "    x[i] = (x[i] + 1) / 2\n",
    "t2 = time.time()\n",
    "\n",
    "print(\"Updated {:d} elements in {:4.3f} seconds.\".format(length, t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_as_function_of_length(length, use_list=False):\n",
    "    if use_list:\n",
    "        x = list(range(length))\n",
    "    else: # otherwise, use a numpy array\n",
    "        x = np.zeros(length)\n",
    "\n",
    "    # now lets loop over all of the elements and add one then divide by two\n",
    "    # we will also use the time package to time how long it takes\n",
    "    t1 = time.time()\n",
    "    if isinstance(x, list):\n",
    "        for i in range(len(x)):\n",
    "            x[i] = (x[i] + 1) / 2\n",
    "    else: # otherwise, assume using a numpy array\n",
    "        x = (x+1) / 2.\n",
    "    t2 = time.time()\n",
    "\n",
    "    print(\"Updated {:d} elements in {:4.3f} seconds.\".format(length, t2 - t1))\n",
    "    return t2 - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m times_list  \u001b[39m=\u001b[39m [ time_as_function_of_length(l, use_list\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)  \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths ]\n\u001b[1;32m      3\u001b[0m times_array \u001b[39m=\u001b[39m [ time_as_function_of_length(l, use_list\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths ] \n",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m times_list  \u001b[39m=\u001b[39m [ time_as_function_of_length(l, use_list\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)  \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths ]\n\u001b[1;32m      3\u001b[0m times_array \u001b[39m=\u001b[39m [ time_as_function_of_length(l, use_list\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths ] \n",
      "Cell \u001b[0;32mIn[5], line 9\u001b[0m, in \u001b[0;36mtime_as_function_of_length\u001b[0;34m(length, use_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m     x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(length)\n\u001b[1;32m      7\u001b[0m \u001b[39m# now lets loop over all of the elements and add one then divide by two\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# we will also use the time package to time how long it takes\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     10\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(x)):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "lengths = 10 ** np.arange(0,5,1)\n",
    "times_list  = [ time_as_function_of_length(l, use_list=True)  for l in lengths ]\n",
    "times_array = [ time_as_function_of_length(l, use_list=False) for l in lengths ] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change the length of the list and keep track of how long the calculation takes as a function of that length.\n",
    "\n",
    "1. Plot the time as a function of list length.\n",
    "\n",
    "1. Now construct a Numpy array from the list `x` and perform the same calculation for several different array lengths.\n",
    "\n",
    "1. Plot the calculation time as a function of array length and add this line to the plot created in step #2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity #2\n",
    "\n",
    "Should you use a for loop in each of the following scenarios? Why or why not?\n",
    "\n",
    "Scenario 1: I want to multiply each element in an array by 10.\n",
    "\n",
    "Scenario 2: I'm writing a quicklook reduction pipleine that will run in real time (so it needs to be as fast as possible). I need to convolve each pixel in an image with the same kernel function.\n",
    "\n",
    "Scenario 3: I'm writing an open-source data anlysis package that will be used and modified by many people. I have 10,000 images that I need to run the same set of functions on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Activity #3\n",
    "\n",
    "Lets load a couple files into a Pandas DataFrame and rearrange and merge them into a single file in a more useful format. `example_data/star_names.json` contains a list star names. If you're runing this notebook on google colab, you'll need to upload the files in codeastro/exampe_data here (click on the file button on the left, then right-click on sample_data, then upload). The `primary_name` column is the primary ID for the star. For each unique `primary_name` there are many `other_names` associated with it. Each `primary_name`+`other_name` combination is stored in a separate row.\n",
    "\n",
    "1. First load the file `example_data/star_names.json` into a Pandas DataFrame. The file is in JSON format so you might look into the `pandas.read_json` function.\n",
    "\n",
    "1. Group the DataFrame on the `primary_name` column and create a custom aggregation function that takes all of the values in the `other_name` column that have the same `primary_name` and converts them into a single string deliminated with a pipe (`|`).\n",
    "\n",
    "1. Load the `example_data/star_props.csv` file into a separate DataFrame and merge this with the grouped DataFrame from step #2.\n",
    "\n",
    "1. Save the result as a new CSV file. The resulting file should look like `example_data/stars_merged.csv`. You may also load this file into Pandas to see what the final DataFrame should look like before saving to a CSV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More on Pandas Functionality \n",
    "(Read through this section on your own. It reads as a continuation of the pandas section above.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sort by the `sample_squared` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=\"sample_squared\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the indices were re-ordered as well. The indices retain information about the original ordering."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also select subsets of the data using conditionals similar to Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = df[df[\"sample\"] <= 4]\n",
    "q1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.groupby` method is used to create Pandas `DataFrameGroupBy` object which can be used to calculate statistics within the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups that share a common sample_base field\n",
    "g = df.groupby(\"sample_base\")\n",
    "\n",
    "# count number of rows within each group\n",
    "print(g.count())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also merge DataFrames together using a common column.\n",
    "\n",
    "Lets create a second DataFrame from the same original list of numbers and calculate the `sample_base` field again. We will also calculate a new column called `sample_sqrt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(x, columns=[\"sample\"])\n",
    "\n",
    "df2[\"sample_base\"] = df2[\"sample\"] // 1\n",
    "df2[\"sample_sqrt\"] = np.sqrt(df2[\"sample\"])\n",
    "df2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add this new column into the original DataFrame by matching up the values on a shared column. In this case we want to match up on the original `sample` column.\n",
    "\n",
    "Sometimes we have multiple DataFrames with one or more overlapping columns and we need to combine into a single DataFrame. This is where merging comes in.\n",
    "\n",
    "Merging is a powerful and complex subject. I frequently find myself [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to lookup various functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(df, df2, on=\"sample\", suffixes=[\"_original\", \"_new\"])\n",
    "merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a column name appears in both DataFrames but is not the column that you are merging on, the strings defined in the `suffixes` argument will be appended to the end of the column names.\n",
    "\n",
    "DataFrames can be written and read from files very easily. Many formats are supported but comma separated values (CSV) is the most commonly used in astronomy. The `read_csv` function can actually read a variety of text file formats by specifying the `delimiter` argument.\n",
    "\n",
    "You can also load a CSV directly from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('sample.csv')\n",
    "\n",
    "!cat sample.csv\n",
    "\n",
    "from_csv = pd.read_csv('sample.csv', index_col=0)\n",
    "from_csv"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "interpreter": {
   "hash": "495f01fe899965e63d8f7bec6c00b11906f9d646a5544c8e6296c1af93828405"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('python3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
